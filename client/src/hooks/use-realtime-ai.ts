import { useRef, useState } from "react";

type FnMap = {
  navigateSection: (args: { section: string }) => {
    success: boolean;
    section?: string;
  };
};

export function useRealtimeAI() {
  const [isConnecting, setIsConnecting] = useState(false);
  const [isConnected, setIsConnected] = useState(false);

  const peerRef = useRef<RTCPeerConnection | null>(null);
  const channelRef = useRef<RTCDataChannel | null>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);

  const fns: FnMap = {
    navigateSection: ({ section }) => {
      const el = document.getElementById(section);
      if (!el) return { success: false };

      const rect = el.getBoundingClientRect();
      const offset =
        rect.top + window.scrollY - window.innerHeight / 2 + rect.height / 2;

      window.scrollTo({ top: offset, behavior: "smooth" });

      return { success: true, section };
    },
  };

  /** ===============================
   * ğŸ“ START CALL
   * =============================== */
  async function startCall(lang: string = "ko") {
    if (isConnecting || isConnected) return;
    setIsConnecting(true);

    try {
      console.log(`[Realtime] Starting call for language: ${lang}`);

      // 1. [ì¤‘ìš”] ì•ˆë“œë¡œì´ë“œ ê¶Œí•œ ì´ìŠˆ í•´ê²°ì„ ìœ„í•´ ë§ˆì´í¬ ìš”ì²­ê³¼ í† í° ìš”ì²­ì„ ë³‘ë ¬ ì‹œì‘
      // ì‚¬ìš©ìì˜ í´ë¦­ ì´ë²¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ê°€ ì‚¬ë¼ì§€ê¸° ì „ì— ë§ˆì´í¬ ê¶Œí•œì„ ìš”ì²­í•´ì•¼ í•¨
      const streamPromise = navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          channelCount: 1,
        },
      });

      const tokenPromise = fetch(`/session/${lang}`).then((res) => res.json());

      // 2. ë‘ ìš”ì²­ì´ ëª¨ë‘ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
      const [stream, data] = await Promise.all([streamPromise, tokenPromise]);

      // ì˜¤ë””ì˜¤ ì•ˆì •í™” (ëª¨ë°”ì¼)
      const isMobile = /iPhone|iPad|iPod|Android/i.test(navigator.userAgent);
      if (isMobile) {
        // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ì„ ì–»ì€ í›„ ì ì‹œ ëŒ€ê¸° (ì„ íƒì‚¬í•­, í•„ìš” ì—†ìœ¼ë©´ ì œê±° ê°€ëŠ¥)
        // await new Promise((r) => setTimeout(r, 500));
      }

      const EPHEMERAL_KEY: string | undefined = data?.client_secret?.value;
      if (!EPHEMERAL_KEY)
        throw new Error("No ephemeral key received from server");

      // 3. [ì¤‘ìš”] Audio Elementë¥¼ DOMì— ê°•ì œ ë¶€ì°© (ì•ˆë“œë¡œì´ë“œ ì¬ìƒ ì •ì±… ìš°íšŒ)
      let audioEl = audioRef.current;
      if (!audioEl) {
        audioEl = document.createElement("audio");
        audioEl.autoplay = true;
        // í™”ë©´ì—ëŠ” ë³´ì´ì§€ ì•Šê²Œ ì²˜ë¦¬
        audioEl.style.display = "none";
        document.body.appendChild(audioEl);
        audioRef.current = audioEl;
      }

      // WebRTC Peer
      const pc = new RTCPeerConnection({
        iceServers: [
          { urls: "stun:stun.l.google.com:19302" },
          { urls: "stun:stun1.l.google.com:19302" },
        ],
        bundlePolicy: "max-bundle",
        rtcpMuxPolicy: "require",
      });
      peerRef.current = pc;

      // ì˜¤ë””ì˜¤ íŠ¸ë™ ìˆ˜ì‹  ì‹œ ì¬ìƒ
      pc.ontrack = (event) => {
        const remoteStream = event.streams[0];
        if (audioEl && remoteStream) {
          audioEl.srcObject = remoteStream;
          audioEl.play().catch((e) => console.warn("Audio play failed:", e));
        }
      };

      pc.onconnectionstatechange = () => {
        console.log("[Realtime] Connection state:", pc.connectionState);
        if (
          pc.connectionState === "failed" ||
          pc.connectionState === "disconnected"
        ) {
          endCall();
        }
      };

      // íšë“í•œ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ì„ PeerConnectionì— ì¶”ê°€
      stream.getTracks().forEach((track) => pc.addTrack(track, stream));

      // ====== DataChannel ======
      const ch = pc.createDataChannel("response");
      channelRef.current = ch;

      ch.onopen = () => {
        console.log("[Realtime] Data channel open");

        const sessionUpdateEvent = {
          type: "session.update",
          session: {
            turn_detection: {
              type: "server_vad",
              threshold: 0.7,
              prefix_padding_ms: 300,
              silence_duration_ms: 800,
            },
            input_audio_transcription: {
              model: "whisper-1",
            },
            tools: [
              {
                type: "function",
                name: "navigateSection",
                description:
                  "Scroll page smoothly to a section (info, announcements, gallery, food, location, program, goods)",
                parameters: {
                  type: "object",
                  properties: {
                    section: {
                      type: "string",
                      enum: [
                        "info",
                        "announcements",
                        "gallery",
                        "food",
                        "location",
                        "program",
                        "goods",
                      ],
                    },
                  },
                  required: ["section"],
                },
              },
            ],
          },
        };

        ch.send(JSON.stringify(sessionUpdateEvent));

        setTimeout(() => {
          ch.send(
            JSON.stringify({
              type: "conversation.item.create",
              item: {
                type: "message",
                role: "system",
                content: [
                  {
                    type: "input_text",
                    text:
                      lang === "en"
                        ? "The call is connected. After preparing your initial response, please say 'Hello! How can I help you with the Siheung Gaetgol Festival?'"
                        : lang === "ja"
                        ? "é€šè©±ãŒæ¥ç¶šã•ã‚Œã¾ã—ãŸã€‚æº–å‚™ãŒå®Œäº†ã—ãŸã‚‰â€¦"
                        : lang === "zh"
                        ? "é€šè¯å·²è¿æ¥ã€‚å‡†å¤‡å¥½åâ€¦"
                        : "í†µí™”ê°€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ˆê¸° ì‘ë‹µ ì¤€ë¹„ í›„ ì¸ì‚¬í•´ì£¼ì„¸ìš”.",
                  },
                ],
              },
            })
          );

          ch.send(JSON.stringify({ type: "response.create" }));
        }, 700);
      };

      ch.onmessage = async (ev) => {
        try {
          const msg = JSON.parse(ev.data);

          if (
            msg.type === "response.function_call_arguments.done" &&
            msg.name in fns
          ) {
            const fn = fns[msg.name as keyof FnMap];
            const args = JSON.parse(msg.arguments);
            const result = fn(args);

            ch.send(
              JSON.stringify({
                type: "conversation.item.create",
                item: {
                  type: "function_call_output",
                  call_id: msg.call_id,
                  output: JSON.stringify(result),
                },
              })
            );

            ch.send(JSON.stringify({ type: "response.create" }));
          }
        } catch (error) {
          console.error("[Realtime] Data channel message error:", error);
        }
      };

      // ====== SDP Offer / Answer ======
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);

      // ICE Gathering ëŒ€ê¸° (í•„ìš”ì‹œ)
      await waitForIceGatheringComplete(pc);

      const model = "gpt-4o-realtime-preview-2025-06-03";

      const sdpResponse = await fetch(
        `https://api.openai.com/v1/realtime?model=${model}`,
        {
          method: "POST",
          headers: {
            Authorization: `Bearer ${EPHEMERAL_KEY}`,
            "Content-Type": "application/sdp",
          },
          body: offer.sdp,
        }
      );

      const answer = {
        type: "answer" as RTCSdpType,
        sdp: await sdpResponse.text(),
      };

      await pc.setRemoteDescription(answer);

      setIsConnected(true);
      console.log("[Realtime] Connected successfully");
    } catch (error) {
      console.error("[Realtime] startCall error:", error);
      endCall();
    } finally {
      setIsConnecting(false);
    }
  }

  /** ===============================
   * ğŸ“ END CALL
   * =============================== */
  function endCall() {
    console.log("[Realtime] Ending callâ€¦");

    try {
      if (channelRef.current) {
        channelRef.current.close();
        channelRef.current = null;
      }

      if (peerRef.current) {
        peerRef.current.getSenders().forEach((s) => s.track?.stop());
        peerRef.current.close();
        peerRef.current = null;
      }

      // [ì¤‘ìš”] ì˜¤ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ì •ë¦¬ ë° DOM ì œê±°
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current.srcObject = null;
        if (audioRef.current.parentNode) {
          audioRef.current.parentNode.removeChild(audioRef.current);
        }
        audioRef.current = null;
      }
    } catch (err) {
      console.warn("[Realtime] endCall cleanup error:", err);
    }

    setIsConnected(false);
    setIsConnecting(false);
  }

  return { startCall, endCall, isConnecting, isConnected };
}

/** ICE Gathering ì™„ë£Œ ëŒ€ê¸° */
function waitForIceGatheringComplete(pc: RTCPeerConnection): Promise<void> {
  if (pc.iceGatheringState === "complete") return Promise.resolve();

  return new Promise((resolve) => {
    const check = () => {
      if (pc.iceGatheringState === "complete") {
        pc.removeEventListener("icegatheringstatechange", check);
        resolve();
      }
    };
    pc.addEventListener("icegatheringstatechange", check);
  });
}
