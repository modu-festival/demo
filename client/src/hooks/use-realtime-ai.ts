import { useRef, useState } from "react";

type FnMap = {
  navigateSection: (args: { section: string }) => {
    success: boolean;
    section?: string;
  };
};

export function useRealtimeAI() {
  const [isConnecting, setIsConnecting] = useState(false);
  const [isConnected, setIsConnected] = useState(false);

  const peerRef = useRef<RTCPeerConnection | null>(null);
  const channelRef = useRef<RTCDataChannel | null>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);

  const fns: FnMap = {
    navigateSection: ({ section }) => {
      const el = document.getElementById(section);
      if (!el) return { success: false };

      const rect = el.getBoundingClientRect();
      const offset =
        rect.top + window.scrollY - window.innerHeight / 2 + rect.height / 2;

      window.scrollTo({ top: offset, behavior: "smooth" });

      return { success: true, section };
    },
  };

  /** ===============================
   * ðŸ“ž START CALL
   * =============================== */
  async function startCall(lang: string = "ko") {
    if (isConnecting || isConnected) return;
    setIsConnecting(true);

    try {
      console.log(`[Realtime] 1. Starting call for language: ${lang}`);

      // 1. ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ & í† í° ë°œê¸‰ ë³‘ë ¬ ì‹œìž‘ (ì œìŠ¤ì²˜ ìœ íš¨ ì‹œê°„ í™•ë³´)
      const streamPromise = navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          channelCount: 1,
        },
      });

      const tokenPromise = fetch(`/session/${lang}`).then((res) => res.json());

      console.log("[Realtime] 2. Waiting for permissions and token...");

      // 2. ëŒ€ê¸°
      const [stream, data] = await Promise.all([streamPromise, tokenPromise]);

      console.log("[Realtime] 3. Permissions granted & Token received");

      const EPHEMERAL_KEY: string | undefined = data?.client_secret?.value;
      if (!EPHEMERAL_KEY)
        throw new Error("No ephemeral key received from server");

      // 3. Audio Element DOM ë¶€ì°© (ì•ˆë“œë¡œì´ë“œ ì •ì±… ìš°íšŒ)
      let audioEl = audioRef.current;
      if (!audioEl) {
        audioEl = document.createElement("audio");
        audioEl.autoplay = true;
        audioEl.style.display = "none";
        document.body.appendChild(audioEl);
        audioRef.current = audioEl;
      }

      // WebRTC Peer ìƒì„±
      const pc = new RTCPeerConnection({
        iceServers: [
          { urls: "stun:stun.l.google.com:19302" },
          { urls: "stun:stun1.l.google.com:19302" },
        ],
        bundlePolicy: "max-bundle",
        rtcpMuxPolicy: "require",
      });
      peerRef.current = pc;

      // íŠ¸ëž™ ìˆ˜ì‹  ì‹œ ìž¬ìƒ
      pc.ontrack = (event) => {
        const remoteStream = event.streams[0];
        if (audioEl && remoteStream) {
          console.log("[Realtime] Audio track received");
          audioEl.srcObject = remoteStream;
          audioEl.play().catch((e) => console.warn("Audio play failed:", e));
        }
      };

      // ë§ˆì´í¬ íŠ¸ëž™ ì¶”ê°€
      stream.getTracks().forEach((track) => pc.addTrack(track, stream));

      // DataChannel ì„¤ì •
      const ch = pc.createDataChannel("response");
      channelRef.current = ch;

      ch.onopen = () => {
        console.log("[Realtime] Data channel open");

        const sessionUpdateEvent = {
          type: "session.update",
          session: {
            turn_detection: {
              type: "server_vad",
              threshold: 0.7,
              prefix_padding_ms: 300,
              silence_duration_ms: 800,
            },
            input_audio_transcription: { model: "whisper-1" },
            tools: [
              {
                type: "function",
                name: "navigateSection",
                description:
                  "Scroll page smoothly to a section (info, announcements, gallery, food, location, program, goods)",
                parameters: {
                  type: "object",
                  properties: {
                    section: {
                      type: "string",
                      enum: [
                        "info",
                        "announcements",
                        "gallery",
                        "food",
                        "location",
                        "program",
                        "goods",
                      ],
                    },
                  },
                  required: ["section"],
                },
              },
            ],
          },
        };
        ch.send(JSON.stringify(sessionUpdateEvent));

        setTimeout(() => {
          ch.send(
            JSON.stringify({
              type: "conversation.item.create",
              item: {
                type: "message",
                role: "system",
                content: [
                  {
                    type: "input_text",
                    text:
                      lang === "en"
                        ? "The call is connected. After preparing your initial response, please say 'Hello! How can I help you with the Siheung Gaetgol Festival?'"
                        : lang === "ja"
                        ? "é€šè©±ãŒæŽ¥ç¶šã•ã‚Œã¾ã—ãŸã€‚æº–å‚™ãŒå®Œäº†ã—ãŸã‚‰â€¦"
                        : lang === "zh"
                        ? "é€šè¯å·²è¿žæŽ¥ã€‚è¯·æ‰“æ‹›å‘¼ã€‚"
                        : "í†µí™”ê°€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ˆê¸° ì‘ë‹µ ì¤€ë¹„ í›„ ì¸ì‚¬í•´ì£¼ì„¸ìš”.",
                  },
                ],
              },
            })
          );
          ch.send(JSON.stringify({ type: "response.create" }));
        }, 700);
      };

      ch.onmessage = async (ev) => {
        try {
          const msg = JSON.parse(ev.data);
          if (
            msg.type === "response.function_call_arguments.done" &&
            msg.name in fns
          ) {
            const fn = fns[msg.name as keyof FnMap];
            const args = JSON.parse(msg.arguments);
            const result = fn(args);
            ch.send(
              JSON.stringify({
                type: "conversation.item.create",
                item: {
                  type: "function_call_output",
                  call_id: msg.call_id,
                  output: JSON.stringify(result),
                },
              })
            );
            ch.send(JSON.stringify({ type: "response.create" }));
          }
        } catch (e) {
          console.error(e);
        }
      };

      // SDP Offer ìƒì„±
      console.log("[Realtime] 4. Creating Offer...");
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);

      console.log("[Realtime] 5. Waiting for ICE Candidates...");

      // âœ… [í•µì‹¬] ICE Gathering íƒ€ìž„ì•„ì›ƒ ì ìš© (ìµœëŒ€ 2ì´ˆ ëŒ€ê¸°)
      await waitForIceGatheringComplete(pc);

      console.log("[Realtime] 6. Sending SDP to OpenAI...");

      const baseUrl = "https://api.openai.com/v1/realtime";
      const model = "gpt-4o-realtime-preview-2025-06-03";

      const sdpResponse = await fetch(`${baseUrl}?model=${model}`, {
        method: "POST",
        headers: {
          Authorization: `Bearer ${EPHEMERAL_KEY}`,
          "Content-Type": "application/sdp",
        },
        body: offer.sdp,
      });

      if (!sdpResponse.ok) {
        throw new Error(`Server responded with ${sdpResponse.status}`);
      }

      console.log("[Realtime] 7. Received Answer SDP");
      const answerSdp = await sdpResponse.text();
      await pc.setRemoteDescription({ type: "answer", sdp: answerSdp });

      setIsConnected(true);
      console.log("[Realtime] âœ… Connected successfully!");
    } catch (error) {
      console.error("[Realtime] startCall error:", error);
      alert(
        `ì—°ê²° ì˜¤ë¥˜: ${error instanceof Error ? error.message : "ì•Œ ìˆ˜ ì—†ìŒ"}`
      );
      endCall();
    } finally {
      setIsConnecting(false);
    }
  }

  function endCall() {
    console.log("[Realtime] Ending callâ€¦");
    if (channelRef.current) {
      channelRef.current.close();
      channelRef.current = null;
    }
    if (peerRef.current) {
      peerRef.current.getSenders().forEach((s) => s.track?.stop());
      peerRef.current.close();
      peerRef.current = null;
    }
    if (audioRef.current) {
      audioRef.current.pause();
      audioRef.current.srcObject = null;
      if (audioRef.current.parentNode) {
        audioRef.current.parentNode.removeChild(audioRef.current);
      }
      audioRef.current = null;
    }
    setIsConnected(false);
    setIsConnecting(false);
  }

  return { startCall, endCall, isConnecting, isConnected };
}

/** * ICE Gathering ì™„ë£Œ ëŒ€ê¸° í•¨ìˆ˜ (íƒ€ìž„ì•„ì›ƒ ì¶”ê°€ ë²„ì „)
 */
function waitForIceGatheringComplete(pc: RTCPeerConnection): Promise<void> {
  return new Promise((resolve) => {
    if (pc.iceGatheringState === "complete") {
      resolve();
      return;
    }

    const check = () => {
      if (pc.iceGatheringState === "complete") {
        pc.removeEventListener("icegatheringstatechange", check);
        resolve();
      }
    };

    pc.addEventListener("icegatheringstatechange", check);

    // â³ 2ì´ˆê°€ ì§€ë‚˜ë„ ì™„ë£Œ ì•ˆ ë˜ë©´ ê°•ì œ ì§„í–‰
    setTimeout(() => {
      if (pc.iceGatheringState !== "complete") {
        console.warn(
          "[Realtime] ICE gathering timed out, proceeding anyway..."
        );
        pc.removeEventListener("icegatheringstatechange", check);
        resolve();
      }
    }, 2000);
  });
}
