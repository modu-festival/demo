import { useRef, useState } from "react";

type FnMap = {
  navigateSection: (args: { section: string }) => {
    success: boolean;
    section?: string;
  };
};

export function useRealtimeAI() {
  const [isConnecting, setIsConnecting] = useState(false);
  const [isConnected, setIsConnected] = useState(false);

  const peerRef = useRef<RTCPeerConnection | null>(null);
  const channelRef = useRef<RTCDataChannel | null>(null);

  const fns: FnMap = {
    navigateSection: ({ section }) => {
      const el = document.getElementById(section);
      if (!el) return { success: false };

      const rect = el.getBoundingClientRect();
      const offset =
        rect.top + window.scrollY - window.innerHeight / 2 + rect.height / 2;

      window.scrollTo({ top: offset, behavior: "smooth" });

      return { success: true, section };
    },
  };

  async function startCall() {
    setIsConnecting(true);
    try {
      // âœ… ì„œë²„ì—ì„œ session ìƒì„±
      const tokenRes = await fetch("/session");
      const data = await tokenRes.json();
      const EPHEMERAL_KEY: string | undefined = data?.client_secret?.value;
      if (!EPHEMERAL_KEY)
        throw new Error("No ephemeral key received from server");

      // WebRTC ì—°ê²° ì„¤ì • ìµœì í™”
      const pc = new RTCPeerConnection({
        iceServers: [
          { urls: "stun:stun.l.google.com:19302" },
          { urls: "stun:stun1.l.google.com:19302" },
        ],
        bundlePolicy: "max-bundle",
        rtcpMuxPolicy: "require",
      });
      peerRef.current = pc;

      // ðŸŽ§ ì˜¤ë””ì˜¤ ì¶œë ¥ ì„¤ì • - í’ˆì§ˆ ê°œì„ 
      const audio = new Audio();
      audio.autoplay = true;
      audio.volume = 0.8; // ë³¼ë¥¨ ì¡°ì ˆ

      pc.ontrack = (event) => {
        const stream = event.streams[0];
        if (stream) {
          // ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì„¤ì • ê°œì„ 
          const audioTracks = stream.getAudioTracks();
          audioTracks.forEach((track) => {
            // ì˜¤ë””ì˜¤ íŠ¸ëž™ ì„¤ì • ìµœì í™”
            if (track.getSettings) {
              const settings = track.getSettings();
              console.log("Audio track settings:", settings);
            }
          });

          audio.srcObject = stream;
          audio.play().catch((e) => console.warn("Audio play failed:", e));
        }
      };

      pc.onconnectionstatechange = () => {
        if (pc.connectionState === "connected") {
          console.log("âœ… ì—°ê²° ì„±ê³µ");
        }
      };

      // ðŸŽ™ï¸ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì¶”ê°€ - ê³ í’ˆì§ˆ ì˜¤ë””ì˜¤ ì„¤ì •
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 48000,
          channelCount: 1,
        },
      });

      // ì˜¤ë””ì˜¤ íŠ¸ëž™ ì„¤ì • ìµœì í™”
      stream.getAudioTracks().forEach((track) => {
        const settings = track.getSettings();
        console.log("Microphone settings:", settings);

        // íŠ¸ëž™ ì œì•½ ì¡°ê±´ ì„¤ì •
        track
          .applyConstraints({
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
          })
          .catch((e) => console.warn("Track constraints failed:", e));
      });

      stream.getTracks().forEach((track) => pc.addTrack(track, stream));

      // ðŸ’¬ ë°ì´í„° ì±„ë„ ìƒì„±
      const ch = pc.createDataChannel("response");
      channelRef.current = ch;

      ch.onopen = () => {
        console.log("âœ… ë°ì´í„° ì±„ë„ open");

        // âœ… ì„œë²„ì˜ instructions, voiceëŠ” ê·¸ëŒ€ë¡œ ë‘ê³  toolsë§Œ ì¶”ê°€
        ch.send(
          JSON.stringify({
            type: "session.update",
            session: {
              tools: [
                {
                  type: "function",
                  name: "navigateSection",
                  description:
                    "Scroll page smoothly to a section (info, announcements, gallery, food, location, program, goods)",
                  parameters: {
                    type: "object",
                    properties: {
                      section: {
                        type: "string",
                        enum: [
                          "info",
                          "announcements",
                          "gallery",
                          "food",
                          "location",
                          "program",
                          "goods",
                        ],
                      },
                    },
                    required: ["section"],
                  },
                },
              ],
            },
          })
        );

        // ì•½ê°„ ì§€ì—° í›„ ì§ì ‘ ì¸ì‚¬ ë©˜íŠ¸ ìš”ì²­ (AIì—ê²Œ â€œë§í•´ë¼â€)
        setTimeout(() => {
          ch.send(
            JSON.stringify({
              type: "conversation.item.create",
              item: {
                type: "message",
                role: "system",
                content: [
                  {
                    type: "input_text",
                    text: "í†µí™”ê°€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ˆê¸° ì‘ë‹µì´ ì¤€ë¹„ê°€ ì „ë¶€ ë˜ê³  ë‚œ í›„, ì‚¬ìš©ìžì—ê²Œ 'ì•ˆë…•í•˜ì„¸ìš”. 20ì£¼ë…„ ì‹œí¥ê°¯ê³¨ì¶•ì œì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²Œ ìžˆìœ¼ì‹ ê°€ìš”?' ë¼ê³  ì¸ì‚¬í•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ë§ì€ í•˜ì§€ ë§ˆì„¸ìš”.",
                  },
                ],
              },
            })
          );

          ch.send(JSON.stringify({ type: "response.create" }));
        }, 800); // 0.8ì´ˆ ì§€ì—°
      };

      // âœ… í•¨ìˆ˜ í˜¸ì¶œ ì²˜ë¦¬
      ch.onmessage = async (ev) => {
        try {
          const msg = JSON.parse(ev.data);

          if (
            msg.type === "response.function_call_arguments.done" &&
            msg.name in fns
          ) {
            const fn = fns[msg.name as keyof FnMap];
            const args = JSON.parse(msg.arguments);
            const result = fn(args);

            ch.send(
              JSON.stringify({
                type: "conversation.item.create",
                item: {
                  type: "function_call_output",
                  call_id: msg.call_id,
                  output: JSON.stringify(result),
                },
              })
            );

            ch.send(JSON.stringify({ type: "response.create" }));
          }
        } catch (error) {
          console.error("Data channel error:", error);
        }
      };

      // ðŸ”„ Offer/Answer êµí™˜
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);
      await waitForIceGatheringComplete(pc);

      const model = "gpt-4o-realtime-preview-2025-06-03";
      const sdpResponse = await fetch(
        `https://api.openai.com/v1/realtime?model=${model}`,
        {
          method: "POST",
          headers: {
            Authorization: `Bearer ${EPHEMERAL_KEY}`,
            "Content-Type": "application/sdp",
          },
          body: offer.sdp,
        }
      );

      const answer = {
        type: "answer" as RTCSdpType,
        sdp: await sdpResponse.text(),
      };
      await pc.setRemoteDescription(answer);

      setIsConnected(true);
    } catch (error) {
      console.error("startCall error:", error);
    } finally {
      setIsConnecting(false);
    }
  }

  function endCall() {
    // ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
    if (peerRef.current) {
      peerRef.current.getSenders().forEach((sender) => {
        if (sender.track) {
          sender.track.stop();
        }
      });
      peerRef.current.close();
    }

    channelRef.current = null;
    setIsConnected(false);
  }

  return { startCall, endCall, isConnecting, isConnected };
}

function waitForIceGatheringComplete(pc: RTCPeerConnection): Promise<void> {
  if (pc.iceGatheringState === "complete") return Promise.resolve();

  return new Promise((resolve) => {
    const check = () => {
      if (pc.iceGatheringState === "complete") {
        pc.removeEventListener("icegatheringstatechange", check);
        resolve();
      }
    };
    pc.addEventListener("icegatheringstatechange", check);
  });
}
